# -*- coding: utf-8 -*-
"""Rnn_2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16SFj28p_wJgOOLGtrjUEkZC6k-uLvT5u
"""

import numpy as np
import pandas as pd
import keras
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Input,Convolution2D,Dropout,Flatten,Dense,MaxPooling2D
from keras.utils import np_utils
import tensorflow
from sklearn.compose import ColumnTransformer
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import jaccard_similarity_score
'''
from google.colab import drive
drive.mount('/content/drive')
'''
dataset=pd.read_csv("./data/Churn_Modelling.csv")

X = dataset.iloc[:, 3:13].values
y = dataset.iloc[:, 13].values

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_X_1 = LabelEncoder()
X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])
labelencoder_X_2 = LabelEncoder()
labelencoder_X_2 = LabelEncoder()
X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])

onehotencoder = OneHotEncoder(categorical_features = [1])
X = onehotencoder.fit_transform(X).toarray()
X = X[:, 1:]



from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

# Feature Scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from keras.layers import Dense

# Initialising the ANN
classifier = Sequential()

#First input layer
#number of node in hidden layer is average of input and output layer
#On experiment by parameter tunning like k4 cross_validataion technique by creating separate set in data set
classifier.add(Dense(output_dim = 6, init = 'uniform', activation='relu', input_dim= 11))

#second hidden layer
classifier.add(Dense(output_dim = 6, init = 'uniform', activation='relu',use_bias=True, bias_initializer=keras.initializers.Constant(0.1)))

#output layer
classifier.add(Dense(output_dim=1,init='uniform',activation='sigmoid'))

#Compilation
#for multiple values(output) loss:catagorical_crossentropy (loss function)
# metric is used to judge the performance of your model
classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)

#considering the probability of leaving the bank is greeater than 0.4
y_pred_test = classifier.predict(X_test)
y_pred_test =(y_pred_test>0.4)
y_pred_train = classifier.predict(X_train)
y_pred_train =(y_pred_train>0.4)

print("Train set Accuracy: ", metrics.accuracy_score(y_train, y_pred_train))
print("Test set Accuracy: ", metrics.accuracy_score(y_test, y_pred_test))
print("jaccard score (test) is : " , jaccard_similarity_score(y_test,y_pred_test))
#print("F1 score (testing) is : " , f1_score(y_test,y_pred_test,average='macro'))
